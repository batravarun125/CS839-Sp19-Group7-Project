{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "api_key = 'af9e771c79336538f1f72e176a3991be'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:09<00:00,  2.86it/s]\n"
     ]
    }
   ],
   "source": [
    "n = []\n",
    "for i in tqdm(range(200)):\n",
    "    if (i == 39 or i == 79 or i == 119 or i == 159 or i ==199):\n",
    "        time.sleep(10)\n",
    "    movie = requests.get(\"http://api.themoviedb.org/3/discover/movie?api_key=\" + api_key + \"&with_genres=35&sort_by=popularity.desc&language=en-US&page=\" + str(i+1))\n",
    "    movie = movie.json()\n",
    "    for p in movie['results']:\n",
    "        n.append(\"https://www.themoviedb.org/movie/\" + str(p['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('tmbd.txt','w') as f:\n",
    "    for x in n:\n",
    "        f.write(x+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('tmbd.txt','r') as f:\n",
    "    n = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Colnames = ['name', 'year', 'subtext', 'duration', 'genres', 'director', 'stars',]\n",
    "\n",
    "def obtain_attributes(url):\n",
    "    source = requests.get(url)\n",
    "    data = source.text\n",
    "    soup = BeautifulSoup(data,'html.parser')\n",
    "    attr ={}\n",
    "    for p in Colnames:\n",
    "        attr[p] = ''\n",
    "    \n",
    "    title = soup.find(\"meta\",property=\"og:title\")\n",
    "    attr['name'] = title.get('content')\n",
    "    \n",
    "    crew =soup.find_all('li',class_='profile')\n",
    "    directors = []\n",
    "    others = []\n",
    "    for people in crew:\n",
    "        p = people.find_all('p')\n",
    "        if len(p) == 2:\n",
    "            for c in p[1].get_text().split(','):\n",
    "                if c.strip() == 'Director':\n",
    "                    directors.append(p[0].get_text())\n",
    "    attr['director'] = ' & '.join(directors)\n",
    "    \n",
    "    subtext = soup.select_one('div.certification span')\n",
    "    if subtext is not None:\n",
    "        subtext = subtext.string\n",
    "    else:\n",
    "        subtext = 'not available'\n",
    "    attr['subtext'] = subtext\n",
    "    \n",
    "    year = soup.find(\"div\", class_=\"header_poster_wrapper\")\n",
    "    release = year.find('span',class_='release_date')\n",
    "    if release is not None:\n",
    "        attr['year'] = release.get_text().replace('(','').replace(')','')\n",
    "    else:\n",
    "        attr['year'] = 'Not Available'\n",
    "    \n",
    "    bar = soup.find_all('strong')\n",
    "    for c in bar:\n",
    "        if c.text == 'Runtime':\n",
    "            attr['duration'] = c.next_sibling\n",
    "    \n",
    "    genres_all = soup.find('section',class_='genres right_column')\n",
    "    genres = []\n",
    "    for c in genres_all.find_all('li'):\n",
    "        genres.append(c.get_text())\n",
    "    attr['genres'] = ' & '.join(genres)\n",
    "    \n",
    "    casts_source = requests.get(url + '/cast')\n",
    "    casts = []\n",
    "    soup_casts = BeautifulSoup(casts_source.text,'html.parser')\n",
    "    m = soup_casts.find_all('div',class_='info')\n",
    "    for c in m:\n",
    "        if c.find('p',class_='character') is not None:\n",
    "            casts.append(c.find('a',href=True).text)\n",
    "    attr['stars'] = ' & '.join(casts)\n",
    "    \n",
    "    return attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = []\n",
    "for i in n:\n",
    "    attributes.append(obtain_attributes(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('tmdb.csv', 'w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=Colnames)\n",
    "    writer.writeheader()\n",
    "    for data in attributes:\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
