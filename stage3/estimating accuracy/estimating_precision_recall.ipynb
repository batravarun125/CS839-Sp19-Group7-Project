{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep 1: steps to install the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting py_entitymatching\n",
      "  Downloading https://files.pythonhosted.org/packages/ee/d3/2eacdb4ee0e268eb4c041fc2921e880262658b24e15ae470559fb1999eab/py_entitymatching-0.3.1.tar.gz (2.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.0MB 831kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyPrind (from py_entitymatching)\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/b3/c3420d9a05e8fd0677907aab873998afd473af41aaf8d3bc557e8f35832c/PyPrind-2.11.2.tar.gz\n",
      "Collecting cloudpickle>=0.2.1 (from py_entitymatching)\n",
      "  Downloading https://files.pythonhosted.org/packages/6e/bc/67f13115adcce4efc5e4d7f8220fb9a50aaa2b5c7ed460b26cbb76aa76ad/cloudpickle-0.8.1-py2.py3-none-any.whl\n",
      "Collecting pandas-profiling>=1.4.0 (from py_entitymatching)\n",
      "  Downloading https://files.pythonhosted.org/packages/3b/98/e4cae9f4485be5ff589227af4e97dd7ebe60c1372bf6f8d9ccbeb0f90667/pandas-profiling-1.4.2.tar.gz\n",
      "    Complete output from command python setup.py egg_info:\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-build-l428MW/pandas-profiling/setup.py\", line 13, in <module>\n",
      "        with open(path.join(this_directory, 'README.md'), encoding='utf-8') as f:\n",
      "    TypeError: 'encoding' is an invalid keyword argument for this function\n",
      "    \n",
      "    ----------------------------------------\n",
      "\u001b[31mCommand \"python setup.py egg_info\" failed with error code 1 in /tmp/pip-build-l428MW/pandas-profiling/\u001b[0m\n",
      "Collecting scipy\n",
      "  Downloading https://files.pythonhosted.org/packages/81/39/f1457091d0a45a84a2bd7815e2cf6bd45d4fe240728e9ed567cbb17c8abe/scipy-1.2.1-cp27-cp27mu-manylinux1_x86_64.whl (24.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 24.8MB 69kB/s  eta 0:00:011\n",
      "\u001b[?25hCollecting numpy>=1.8.2 (from scipy)\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/72/179a78b565ecf01fe98dab6417581d30acac15c2d93c49f93169ebea99b1/numpy-1.16.3-cp27-cp27mu-manylinux1_x86_64.whl (17.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 17.0MB 100kB/s eta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: numpy, scipy\n",
      "Successfully installed numpy-1.16.3 scipy-1.2.1\n",
      "Collecting numpy\n",
      "  Using cached https://files.pythonhosted.org/packages/e1/72/179a78b565ecf01fe98dab6417581d30acac15c2d93c49f93169ebea99b1/numpy-1.16.3-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.16.3\n",
      "Collecting pandas\n",
      "  Downloading https://files.pythonhosted.org/packages/db/83/7d4008ffc2988066ff37f6a0bb6d7b60822367dcb36ba5e39aa7801fda54/pandas-0.24.2-cp27-cp27mu-manylinux1_x86_64.whl (10.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.1MB 170kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.12.0 (from pandas)\n",
      "  Using cached https://files.pythonhosted.org/packages/e1/72/179a78b565ecf01fe98dab6417581d30acac15c2d93c49f93169ebea99b1/numpy-1.16.3-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting pytz>=2011k (from pandas)\n",
      "  Downloading https://files.pythonhosted.org/packages/3d/73/fe30c2daaaa0713420d0382b16fbb761409f532c56bdcc514bf7b6262bb6/pytz-2019.1-py2.py3-none-any.whl (510kB)\n",
      "\u001b[K    100% |████████████████████████████████| 512kB 3.3MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting python-dateutil>=2.5.0 (from pandas)\n",
      "  Using cached https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl\n",
      "Collecting six>=1.5 (from python-dateutil>=2.5.0->pandas)\n",
      "  Using cached https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Installing collected packages: numpy, pytz, six, python-dateutil, pandas\n",
      "Successfully installed numpy-1.16.3 pandas-0.24.2 python-dateutil-2.8.0 pytz-2019.1 six-1.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install py_entitymatching\n",
    "!pip install scipy\n",
    "!pip install numpy\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep 2: enter the file location on your harddisk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_a = '<table_a_location_downloaded_from_cloudmatcher_loc>'\n",
    "table_b = '<table_a_location_downloaded_from_cloudmatcher_loc>'\n",
    "candidate_set = '<candidate_set_downloaded_from_cloudmatcher_loc>'\n",
    "prediction_set = '<prediction_set_downloaded_from_cloudmatcher_loc>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep 3: reading the files into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = pd.read_csv(table_a)\n",
    "dfb = pd.read_csv(table_b)\n",
    "dfc = pd.read_csv(candidate_set)\n",
    "dfp = pd.read_csv(prediction_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module: debug_blocker\n",
    "# Description: debug the blocking rule using the below script to ensure you are not dropping true matches\n",
    "# Note: You need to run Prep 1 and 2 in order to run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example input format:\n",
    "# Format of table_a:\n",
    "# _id, attribute1, attribute2, ....., attributen\n",
    "\n",
    "# Format of table_b:\n",
    "# _id, attribute1, attribute2, ....., attributen\n",
    "\n",
    "# Format of candidate_set\n",
    "# A_id,B_id\n",
    "# where A_id is _id from table_a and B_id is the _id column value from table_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import py_entitymatching as em\n",
    "import pandas as pd\n",
    "\n",
    "def run_debug_blocker(table_a, table_b, table_a_key, table_b_key, candidate_set):\n",
    "    dfl = em.read_csv_metadata(table_a, key=table_a_key)\n",
    "    dfr = em.read_csv_metadata(table_b, key=table_b_key)\n",
    "\n",
    "    # reading the candidate set and adding key\n",
    "    dfcand = pd.read_csv(candidate_set)\n",
    "    dfcand.drop_duplicates(inplace=True)\n",
    "    dfcand.to_csv('cand_set_with_index.csv', index_label='id')\n",
    "\n",
    "    dfcset = em.read_csv_metadata('cand_set_with_index.csv', key='id', ltable=dfl, \n",
    "                                  rtable=dfr, fk_ltable='A_id', fk_rtable='B_id')\n",
    "\n",
    "    # running debug blocker to identify the records in A x B \\ C\n",
    "    debug_file = em.debug_blocker(dfcset, dfl, dfr)\n",
    "    \n",
    "    return debug_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_file = run_debug_blocker(table_a, table_b, table_a_key, table_b_key, candidate_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module: estimate_precision_recall\n",
    "# Description: the below code helps you get an estimation of P/R on the candidate set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from numpy import sqrt\n",
    "\n",
    "delta = .05\n",
    "Z = norm.ppf(1 - (delta / 2))\n",
    "\n",
    "def estimate_PR(labeled_pairs, reduced_cands, predicted_matches):\n",
    "    '''\n",
    "    labeled_pairs - a pandas dataframe with schema id1,id2,label\n",
    "                    Note label needs to be Boolean\n",
    "\n",
    "    reduced_cands - a pandas dataframe with schema id1,id2\n",
    "    predicted_matches - a pandas dataframe with schema id1,id2\n",
    "    \n",
    "    return:\n",
    "        ( (recall lower bound, recall upper bound), (precision lower bound, precision upper bound) )\n",
    "    '''\n",
    "\n",
    "    reduced_cand_set = set(zip(reduced_cands.id1, reduced_cands.id2))\n",
    "    predicted_matches = set(zip(predicted_matches.id1, predicted_matches.id2))\n",
    "    \n",
    "    # estimate the recall\n",
    "    # number of positives in the labeled sample\n",
    "    actual_pos = float(labeled_pairs.label.sum())\n",
    "    # the maximum number of postives in the candidate set\n",
    "    max_actual_pos = float(actual_pos + len(reduced_cand_set) - len(labeled_pairs))\n",
    "    \n",
    "    # true positives in the labeled sample\n",
    "    true_pos = float(labeled_pairs.apply(lambda x : (x['id1'], x['id2']) in predicted_matches and x['label'], axis=1).sum())\n",
    "    #estimated recall\n",
    "    recall = float(true_pos / actual_pos)\n",
    "\n",
    "    recall_error = Z * sqrt( ((recall * (1 - recall)) / actual_pos) * ((max_actual_pos - actual_pos) / max_actual_pos - 1) )\n",
    "\n",
    "\n",
    "    # estimate Precision\n",
    "    labeled_set  = set(zip(labeled_pairs.id1, labeled_pairs.id2))\n",
    "    predicted_pos = float(len(labeled_set & predicted_matches))\n",
    "    \n",
    "    predicted_pos_in_reduced_cand_set = float(len(reduced_cand_set & predicted_matches))\n",
    "    \n",
    "    alpha =  predicted_pos_in_reduced_cand_set / len(predicted_matches)\n",
    "    precision = alpha * (true_pos / predicted_pos)\n",
    "    \n",
    "    precision_error = alpha * Z * sqrt( ((precision * (1 - precision)) / predicted_pos) * (float((len(predicted_matches) - predicted_pos)) / (len(predicted_matches)  - 1)) )\n",
    "\n",
    "    return ((recall - recall_error, recall + recall_error),\n",
    "            (precision - precision_error, precision + precision_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(estimate_PR(labeled, reduced_cand_set, dfp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
