{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import recall_score,precision_score,f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames=! ls ../data/*.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Split datasets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,X_test,_,_ = train_test_split(filenames,np.arange(len(filenames)),test_size = 0.2,random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = []\n",
    "for file in X_train:\n",
    "    with open(file,'r') as f:\n",
    "        docs.append(f.readlines())\n",
    "\n",
    "documents = []\n",
    "for x in docs:\n",
    "    paragraphs = ''\n",
    "    for y in x:\n",
    "        z = re.sub('\\n',' ',y)\n",
    "        z = re.sub('\\'',' \\'',z)\n",
    "        if z != '':\n",
    "            paragraphs += z\n",
    "    documents.append(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ls: ./data/*.txt: No such file or directory'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ce5f2552239b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mtest_docs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_documents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ls: ./data/*.txt: No such file or directory'"
     ]
    }
   ],
   "source": [
    "test_docs = []\n",
    "for file in X_test:\n",
    "    with open(file,'r') as f:\n",
    "        test_docs.append(f.readlines())\n",
    "test_documents = []\n",
    "for x in test_docs:\n",
    "    paragraphs = ''\n",
    "    for y in x:\n",
    "        z = re.sub('\\n',' ',y)\n",
    "        z = re.sub('\\'',' \\'',z)\n",
    "        if z != '':\n",
    "            paragraphs += z\n",
    "    test_documents.append(paragraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Add stopwords*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = [x.capitalize() for x in stopwords.words('english') if re.findall('\\'',x)==[]]\n",
    "stop += ['Never', 'Aha', 'Ah', 'Oh', 'Eh', 'Really', 'Well', 'Yes', 'No', 'Please', 'Ha-ha-ha', 'Alas', 'A-a-ah', 'Next', 'After', 'Hm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = ['Mr','Miss','Madame','Madam','Doctor','Father','Dr','Ser','Lord','Prince','Princess','King','Queen',\n",
    "           'Dear','Mother','Uncle','Mrs','Sir','Sister','Brother','Bishop','Lieutenant-General','Captain',\n",
    "          'Mayor','General','Son','Children','Granny']\n",
    "s_prefix = [x.lower() for x in prefix]\n",
    "s_prefix += prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Construct predictors **\n",
    "\n",
    "*Define functions for pre-process*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createlist(docs):\n",
    "    linkedlist = pd.DataFrame({'prev':[],'word':[],'next':[],'y':[]})\n",
    "    for doc in docs:\n",
    "        doc = re.sub('[\\.;!\\?:\\(\\)\\+,]','',doc)\n",
    "        do = ''\n",
    "        ts = word_tokenize(doc)\n",
    "        ts = [t for t in ts if len(t) > 1]\n",
    "        for t in ts:\n",
    "            if t in stop:\n",
    "                continue\n",
    "            elif t in prefix:\n",
    "                t = t.lower()\n",
    "                do = do + t + ' '\n",
    "            else:\n",
    "                do = do + t + ' '\n",
    "    \n",
    "        do = re.sub('([A-Z][A-Za-z]+) ([A-Z][A-Za-z]+) ([A-Z][A-Za-z]+)','\\\\1_\\\\2_\\\\3',do)\n",
    "        do = re.sub('([A-Z][A-Za-z]+) ([A-Z][A-Za-z]+)','\\\\1_\\\\2',do)\n",
    "        tokens = word_tokenize(do)\n",
    "        for i,x in enumerate(tokens):\n",
    "            if i == 0:\n",
    "                y = (re.sub('\\*','',x)!=x)\n",
    "                linkedlist = linkedlist.append(pd.DataFrame({'prev':[None],'word':[x],'next':[tokens[1]],'y':[y]}))\n",
    "            elif i == len(tokens)-1:\n",
    "                y = (re.sub('\\*','',x)!=x)\n",
    "                linkedlist = linkedlist.append(pd.DataFrame({'prev':[tokens[i-1]],'word':[x],'next':[None],'y':[y]}))\n",
    "            else:\n",
    "                y = (re.sub('\\*','',x)!=x)\n",
    "                linkedlist = linkedlist.append(pd.DataFrame({'prev':[tokens[i-1]],'word':[x],'next':[tokens[i+1]],'y':[y]}))\n",
    "    return linkedlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For training set I*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linkedlist = createlist(documents)\n",
    "\n",
    "linkedlist.word = linkedlist.word.apply(lambda x: re.sub('\\*','',x))\n",
    "linkedlist.prev = linkedlist.prev.apply(lambda x: re.sub('\\*','',str(x)))\n",
    "linkedlist.next = linkedlist.next.apply(lambda x: re.sub('\\*','',str(x)))\n",
    "linkedlist.word = linkedlist.word.apply(lambda x: re.sub('``','\"',x))\n",
    "linkedlist.prev = linkedlist.prev.apply(lambda x: re.sub('``','\"',str(x)))\n",
    "linkedlist.next = linkedlist.next.apply(lambda x: re.sub('``','\"',str(x)))\n",
    "\n",
    "yes = []\n",
    "for i,x in enumerate(linkedlist.word.values):\n",
    "    if x[0].isupper():\n",
    "        yes.append(i)\n",
    "newlist = linkedlist.iloc[yes]\n",
    "newlist = newlist[~newlist.word.isin(['\\'','\"','\\'\\''])]\n",
    "newlist = newlist.reset_index(drop=True)\n",
    "\n",
    "for i in range(newlist.shape[0]):\n",
    "    tags = pos_tag(newlist.loc[i,['prev','word','next']].values)\n",
    "    if tags[0][0] == '\"':\n",
    "        tags[0] = ('\"','SB')\n",
    "    elif tags[0][0] == 'that':\n",
    "        tags[0] = ('that','SB')\n",
    "    if tags[2][0] == '\"':\n",
    "        tags[2] = ('\"','SB')\n",
    "    elif tags[2][0] == 'that':\n",
    "        tags[2] = ('that','SB')\n",
    "    if tags[2][0] in  ['can', 'could', 'may', 'might', 'must', 'will', 'would', 'should', 'shall',\n",
    "                      'herself', 'himself', 'themself','lies', 'rushes', 'rode', 'lays']:\n",
    "        tags[2] = (tags[2][0], 'VB')\n",
    "    newlist.loc[i,'has_verb'] = (tags[0][1].startswith('V')) | (tags[2][1].startswith('V'))\n",
    "\n",
    "newlist['next_\\'s'] = newlist.next.apply(lambda x: x== '\\'s')\n",
    "newlist['prefix'] = newlist.prev.apply(lambda x: x in s_prefix)\n",
    "newlist['prev_the'] = newlist.prev.apply(lambda x: x != 'the')\n",
    "newlist['next_of'] = newlist.prev.apply(lambda x: x == 'of')\n",
    "newlist['next_who'] = newlist.next.apply(lambda x: (x== 'who')|(x=='whose')|(x=='whom'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For testing set J*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testlist = createlist(test_documents)\n",
    "\n",
    "testlist.word = testlist.word.apply(lambda x: re.sub('\\*','',x))\n",
    "testlist.prev = testlist.prev.apply(lambda x: re.sub('\\*','',str(x)))\n",
    "testlist.next = testlist.next.apply(lambda x: re.sub('\\*','',str(x)))\n",
    "testlist.word = testlist.word.apply(lambda x: re.sub('``','\"',x))\n",
    "testlist.prev = testlist.prev.apply(lambda x: re.sub('``','\"',str(x)))\n",
    "testlist.next = testlist.next.apply(lambda x: re.sub('``','\"',str(x)))\n",
    "\n",
    "yes = []\n",
    "for i,x in enumerate(testlist.word.values):\n",
    "    if x[0].isupper():\n",
    "        yes.append(i)\n",
    "newtestlist = testlist.iloc[yes]\n",
    "newtestlist = newtestlist[~newtestlist.word.isin(['\\'','\"','\\'\\''])]\n",
    "newtestlist = newtestlist.reset_index(drop=True)\n",
    "\n",
    "for i in range(newtestlist.shape[0]):\n",
    "    tags = pos_tag(newtestlist.loc[i,['prev','word','next']].values)\n",
    "    if tags[0][0] == '\"':\n",
    "        tags[0] = ('\"','SB')\n",
    "    elif tags[0][0] == 'that':\n",
    "        tags[0] = ('that','SB')\n",
    "    if tags[2][0] == '\"':\n",
    "        tags[2] = ('\"','SB')\n",
    "    elif tags[2][0] == 'that':\n",
    "        tags[2] = ('that','SB')\n",
    "    if tags[2][0] in  ['can', 'could', 'may', 'might', 'must', 'will', 'would', 'should', 'shall',\n",
    "                       'herself', 'himself', 'themself',\n",
    "                      'lies', 'rushes', 'rode', 'lays']:\n",
    "        tags[2] = (tags[2][0], 'VB')\n",
    "    newtestlist.loc[i,'has_verb'] = (tags[0][1].startswith('V')) | (tags[2][1].startswith('V'))\n",
    "\n",
    "newtestlist['next_\\'s'] = newtestlist.next.apply(lambda x: x== '\\'s')\n",
    "newtestlist['prefix'] = newtestlist.prev.apply(lambda x: x in s_prefix)\n",
    "newtestlist['prev_the'] = newtestlist.prev.apply(lambda x: x != 'the')\n",
    "newtestlist['next_of'] = newtestlist.prev.apply(lambda x: x == 'of')\n",
    "newtestlist['next_who'] = newtestlist.next.apply(lambda x: (x== 'who')| (x =='whom') | (x== 'whose'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Finalize datasets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = newlist[['has_verb','prefix','next_\\'s','prev_the','next_of','next_who']]\n",
    "Y_train = newlist.y\n",
    "X_test = newtestlist[['has_verb','prefix','next_\\'s','prev_the','next_of','next_who']]\n",
    "Y_test = newtestlist.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding optimal models**\n",
    "\n",
    "*Cross-Validation Results*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X4linear, Y4linear = shuffle(X_train,Y_train)\n",
    "threshold = 0.8\n",
    "train_size = len(X4linear)\n",
    "#print train_size\n",
    "subset_size = np.int(train_size/5)\n",
    "#print subset_size\n",
    "p_list = []\n",
    "r_list = []\n",
    "f1_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regr_precission: 0.854413\n",
      "regr_recall: 0.401592\n",
      "regr_f1: 0.483291\n",
      "lr_precision: 0.738015\n",
      "lr_recall: 0.746216\n",
      "lr_f1: 0.733354\n",
      "rf_precision: 0.743470\n",
      "rf_recall: 0.751781\n",
      "rf_f1: 0.737265\n",
      "svm_precision: 0.743693\n",
      "svm_recall: 0.751781\n",
      "svm_f1: 0.737585\n",
      "tree_precision: 0.743470\n",
      "tree_recall: 0.751509\n",
      "tree_f1: 0.737265\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 5):\n",
    "    regr = LinearRegression()\n",
    "    cv_train_X = X4linear[0:i*subset_size].append(X4linear[(i+1)*subset_size:])\n",
    "    cv_train_Y = Y4linear[0:i*subset_size].append(Y4linear[(i+1)*subset_size:])\n",
    "    cv_test_X = X4linear[i*subset_size:(i+1)*subset_size]\n",
    "    cv_test_Y = Y4linear[i*subset_size:(i+1)*subset_size]\n",
    "    regr.fit(cv_train_X, cv_train_Y)\n",
    "    cv_predict = regr.predict(cv_test_X)\n",
    "    cv_predict = [int(y>threshold) for y in cv_predict]\n",
    "    p_list.append(precision_score(cv_test_Y, cv_predict))\n",
    "    r_list.append(recall_score(cv_test_Y, cv_predict))\n",
    "    f1_list.append(f1_score(cv_test_Y, cv_predict))\n",
    "print('regr_precission: %f' %np.average(p_list))\n",
    "print('regr_recall: %f' %np.average(r_list))\n",
    "print('regr_f1: %f' %np.average(f1_list))\n",
    "\n",
    "lr = LogisticRegression(max_iter = 200,solver = 'lbfgs')\n",
    "rf = RandomForestClassifier(criterion = 'entropy',max_depth=20,n_estimators=5)\n",
    "svm = SVC(gamma='scale')\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "scores = cross_val_score(lr, X_train, Y_train, scoring='precision_macro', cv=5)\n",
    "print('lr_precision: %f' %scores.mean())\n",
    "scores = cross_val_score(lr, X_train, Y_train, scoring='recall_macro', cv=5)\n",
    "print('lr_recall: %f' %scores.mean())\n",
    "scores = cross_val_score(lr, X_train, Y_train, scoring='f1_macro', cv=5)\n",
    "print('lr_f1: %f' %scores.mean())\n",
    "\n",
    "scores = cross_val_score(rf, X_train, Y_train, scoring='precision_macro', cv=5)\n",
    "print('rf_precision: %f' %scores.mean())\n",
    "scores = cross_val_score(rf, X_train, Y_train, scoring='recall_macro', cv=5)\n",
    "print('rf_recall: %f' %scores.mean())\n",
    "scores = cross_val_score(rf, X_train, Y_train, scoring='f1_macro', cv=5)\n",
    "print('rf_f1: %f' %scores.mean())\n",
    "\n",
    "scores = cross_val_score(svm, X_train, Y_train, scoring='precision_macro', cv=5)\n",
    "print('svm_precision: %f' %scores.mean())\n",
    "scores = cross_val_score(svm, X_train, Y_train, scoring='recall_macro', cv=5)\n",
    "print('svm_recall: %f' %scores.mean())\n",
    "scores = cross_val_score(svm, X_train, Y_train, scoring='f1_macro', cv=5)\n",
    "print('svm_f1: %f' %scores.mean())\n",
    "\n",
    "scores = cross_val_score(tree, X_train, Y_train, scoring='precision_macro', cv=5)\n",
    "print('tree_precision: %f' %scores.mean())\n",
    "scores = cross_val_score(tree, X_train, Y_train, scoring='recall_macro', cv=5)\n",
    "print('tree_recall: %f' %scores.mean())\n",
    "scores = cross_val_score(tree, X_train, Y_train, scoring='f1_macro', cv=5)\n",
    "print('tree_f1: %f' %scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Postprocess with decision tree model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8535211267605634\n",
      "0.6718403547671841\n",
      "0.7518610421836228\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(gamma='scale')\n",
    "svm.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = svm.predict(X_test)\n",
    "print(precision_score(Y_test, Y_pred))\n",
    "print(recall_score(Y_test, Y_pred))\n",
    "print(f1_score(Y_test, Y_pred))\n",
    "cfn = newtestlist.loc[(Y_pred != Y_test) & (Y_pred == 1)]\n",
    "#cfn %check false negative examples\n",
    "cfp = newtestlist.loc[(Y_pred != Y_test) & (Y_test == 1)]\n",
    "#cfp %check false positive examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blacklist=['Janurary','Feburary','March','April','May','June','July','August','September','October','November','December',\n",
    "           'God','Gods','Granny', 'Near', 'Beyond', 'Next', 'Below','Come','Go',\n",
    "           'Persia','Persian','Russia','France','Russians','Viennese','French','Russian','Chinese','German','Latin','United_States',\n",
    "           'London','America','Winterfell','California',\n",
    "           'Children','People','Every','Everyone','Everything','Someone','Something','Anything','Others','Nothing','Many','House',\n",
    "           'One','Two','Three','Four','Five','Six','Seven','Eight','Nine'\n",
    "           'Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday','Yesterday','Tomorrow','Today','Tonight',\n",
    "           'Spring','Summer', 'Autumn', 'Winter','Men', 'Women']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "white = newtestlist.prev.isin(s_prefix)\n",
    "black = newtestlist.word.isin(blacklist)\n",
    "\n",
    "whitetrain = newlist.word.isin(s_prefix)\n",
    "blacktrain = newlist.word.isin(blacklist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9181818181818182\n",
      "0.6718403547671841\n",
      "0.7759282970550576\n"
     ]
    }
   ],
   "source": [
    "Y_pred = svm.predict(X_test)\n",
    "Y_pred[white] = 1\n",
    "Y_pred[black] = 0\n",
    "print(precision_score(Y_test, Y_pred))\n",
    "print(recall_score(Y_test, Y_pred))\n",
    "print(f1_score(Y_test, Y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
